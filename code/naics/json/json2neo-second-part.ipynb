{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "from py2neo import Graph, Node, Relationship\n",
    "import json\n",
    "import Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = Graph(password=\"1234\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get company name \n",
    "company_name_list = g.run(\"MATCH (c:Company) RETURN c.name as name\").data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load naics related data\n",
    "f = open(\"./2012_NAICS_Structure.csv\", \"r\")\n",
    "content = f.read().split(\"\\n\")\n",
    "with open('naics.json') as f:\n",
    "    naics_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get naics code book as a dictionary\n",
    "naics_code_book = {}\n",
    "for line in content:\n",
    "    temp_code = line.split(\",\")[0]\n",
    "    temp_desc = line.split(\",\")[1]\n",
    "    naics_code_book[temp_code] = temp_desc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "BELONGS_TO = Relationship.type(\"SubClassOf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def getKey(item):\n",
    "    return item[0]\n",
    "\n",
    "for obj in naics_data:\n",
    "    name = obj['name'].split(\" \")[0]\n",
    "    l = [(Levenshtein.distance(item['name'].split(\" \")[0],name),item) for item in company_name_list]\n",
    "    l = sorted(l, key=getKey)\n",
    "    company_node = g.nodes.match('Company', name=l[0][1]['name']).first()\n",
    "    \n",
    "    prev = company_node\n",
    "    cur_code = obj['code']\n",
    "    while len(cur_code) > 0:\n",
    "        if cur_code in naics_code_book:\n",
    "            info = naics_code_book[cur_code]\n",
    "            info = info.replace(\"\\\"\",\"\").strip()\n",
    "            if info[-1] == \"T\":\n",
    "                info = info[0:-1]\n",
    "            temp = Node(\"NAICS_CODE\", code=cur_code, description=info)\n",
    "            g.merge(temp, \"NAICS_CODE\", \"code\")\n",
    "            temp_r = BELONGS_TO(prev, temp)\n",
    "            g.create(temp_r)\n",
    "            prev = temp\n",
    "        cur_code = cur_code[0:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('person-birth.json') as f:\n",
    "    person_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "USBORN = Relationship.type(\"USAborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Mark Zuckerberg', 'location': 'New York', 'birth-year': '1984'},\n",
       " {'name': 'Eduardo Saverin', 'location': '', 'birth-year': '1982'},\n",
       " {'name': 'Andrew McCollum', 'location': 'California', 'birth-year': '1983'},\n",
       " {'name': 'Dustin Moskovitz', 'location': 'Florida', 'birth-year': '1984'},\n",
       " {'name': 'Chris Hughes', 'location': 'North Carolina', 'birth-year': '1983'},\n",
       " {'name': 'Bill Gates', 'location': 'Washington', 'birth-year': '1955'},\n",
       " {'name': 'Paul Allen', 'location': 'Washington', 'birth-year': '1953'},\n",
       " {'name': 'Satya Nadella', 'location': '', 'birth-year': '1967'},\n",
       " {'name': 'Larry Page', 'location': 'Massachusetts', 'birth-year': '1973'},\n",
       " {'name': 'Sergey Brin', 'location': '', 'birth-year': '1973'},\n",
       " {'name': 'Sundar Pichai', 'location': '', 'birth-year': '1972'},\n",
       " {'name': 'Steve Jobs', 'location': 'California', 'birth-year': '1955'},\n",
       " {'name': 'Steve Wozniak', 'location': 'California', 'birth-year': '1950'},\n",
       " {'name': 'Ronald Wayne', 'location': 'Ohio', 'birth-year': '1934'},\n",
       " {'name': 'Tim Cook', 'location': 'Alabama', 'birth-year': '1960'},\n",
       " {'name': 'Chad Hurley', 'location': 'Pennsylvania', 'birth-year': '1977'},\n",
       " {'name': 'Steve Chen', 'location': '', 'birth-year': '1978'},\n",
       " {'name': 'Jawed Karim', 'location': '', 'birth-year': '1979'},\n",
       " {'name': 'Susan Wojcicki', 'location': 'California', 'birth-year': '1968'},\n",
       " {'name': 'James Park', 'location': '', 'birth-year': '1977'}]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark Zuckerberg\n",
      "error {'name': 'Mark Zuckerberg', 'location': 'New York', 'birth-year': '1984'}\n",
      "Eduardo Saverin\n",
      "Andrew McCollum\n",
      "error {'name': 'Andrew McCollum', 'location': 'California', 'birth-year': '1983'}\n",
      "Dustin Moskovitz\n",
      "error {'name': 'Dustin Moskovitz', 'location': 'Florida', 'birth-year': '1984'}\n",
      "Chris Hughes\n",
      "error {'name': 'Chris Hughes', 'location': 'North Carolina', 'birth-year': '1983'}\n",
      "Bill Gates\n",
      "error {'name': 'Bill Gates', 'location': 'Washington', 'birth-year': '1955'}\n",
      "Paul Allen\n",
      "error {'name': 'Paul Allen', 'location': 'Washington', 'birth-year': '1953'}\n",
      "Satya Nadella\n",
      "Larry Page\n",
      "error {'name': 'Larry Page', 'location': 'Massachusetts', 'birth-year': '1973'}\n",
      "Sergey Brin\n",
      "Sundar Pichai\n",
      "Steve Jobs\n",
      "error {'name': 'Steve Jobs', 'location': 'California', 'birth-year': '1955'}\n",
      "Steve Wozniak\n",
      "error {'name': 'Steve Wozniak', 'location': 'California', 'birth-year': '1950'}\n",
      "Ronald Wayne\n",
      "error {'name': 'Ronald Wayne', 'location': 'Ohio', 'birth-year': '1934'}\n",
      "Tim Cook\n",
      "error {'name': 'Tim Cook', 'location': 'Alabama', 'birth-year': '1960'}\n",
      "Chad Hurley\n",
      "error {'name': 'Chad Hurley', 'location': 'Pennsylvania', 'birth-year': '1977'}\n",
      "Steve Chen\n",
      "Jawed Karim\n",
      "Susan Wojcicki\n",
      "error {'name': 'Susan Wojcicki', 'location': 'California', 'birth-year': '1968'}\n",
      "James Park\n"
     ]
    }
   ],
   "source": [
    "for p in person_data:\n",
    "        print(p[\"name\"])\n",
    "        person_node = g.nodes.match('Person', name=p[\"name\"]).first()\n",
    "        person_node['DOB'] = int( p['birth-year'])\n",
    "        #g.push(person_node)\n",
    "\n",
    "        if len(p[\"location\"]) > 0:\n",
    "            temp = Node(\"State\", name=p[\"location\"])\n",
    "            g.merge(temp, \"State\", \"name\")\n",
    "        else:\n",
    "            continue\n",
    "        temp_r = USBORN(person_node, temp)\n",
    "        g.create(temp_r)\n",
    "\n",
    "        print(\"error\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('goole-pro-text.json') as f:\n",
    "    gp_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRO = Relationship.type(\"Produce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_node = g.nodes.match('Company', name=\"Google\").first()\n",
    "for p in gp_data:\n",
    "    sentence = p[\"text\"].split(\". \")[0] + \".\"\n",
    "    temp = Node(\"Product\", name=p[\"name\"], desc=sentence)\n",
    "    g.merge(temp, \"Product\", \"name\")\n",
    "    temp_r = PRO(company_node, temp)\n",
    "    g.create(temp_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('facebook-pro-text.json') as f:\n",
    "    gp_data = json.load(f)\n",
    "company_node = g.nodes.match('Company', name=\"Facebook\").first()\n",
    "for p in gp_data:\n",
    "    sentence = p[\"text\"].split(\". \")[0] + \".\"\n",
    "    temp = Node(\"Product\", name=p[\"name\"], desc=sentence)\n",
    "    g.merge(temp, \"Product\", \"name\")\n",
    "    temp_r = PRO(company_node, temp)\n",
    "    g.create(temp_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('microsoft-pro-text.json') as f:\n",
    "    gp_data = json.load(f)\n",
    "company_node = g.nodes.match('Company', name=\"Microsoft\").first()\n",
    "for p in gp_data:\n",
    "    sentence = p[\"text\"].split(\". \")[0] + \".\"\n",
    "    if \"may refer to\" in sentence:\n",
    "        continue\n",
    "    temp = Node(\"Product\", name=p[\"name\"], desc=sentence)\n",
    "    g.merge(temp, \"Product\", \"name\")\n",
    "    temp_r = PRO(company_node, temp)\n",
    "    g.create(temp_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('apple-pro-text.json') as f:\n",
    "    gp_data = json.load(f)\n",
    "company_node = g.nodes.match('Company', name=\"Apple Inc.\").first()\n",
    "for p in gp_data:\n",
    "    sentence = p[\"text\"].split(\". \")[0] + \".\"\n",
    "    if \"may refer to\" in sentence:\n",
    "        continue\n",
    "    temp = Node(\"Product\", name=p[\"name\"], desc=sentence)\n",
    "    g.merge(temp, \"Product\", \"name\")\n",
    "    temp_r = PRO(company_node, temp)\n",
    "    g.create(temp_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('products.json', encoding='utf-8-sig') as f:\n",
    "    pro = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for p in pro:\n",
    "    out.append(p['p']['properties'])\n",
    "with open('out.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(out, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic set-ups \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_json(\"out.json\")\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer(min_df=1, stop_words=\"english\") \n",
    "tfidf = vect.fit_transform(data[\"desc\"])  \n",
    "pairwise_similarity = tfidf * tfidf.T \n",
    "sorted(pairwise_similarity.toarray()[0])[0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
